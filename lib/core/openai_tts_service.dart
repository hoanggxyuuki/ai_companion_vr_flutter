import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';
import 'package:http/http.dart' as http;
import 'package:path_provider/path_provider.dart';
import 'package:audioplayers/audioplayers.dart';
import 'package:flutter/foundation.dart';

class OpenAITTSService {
  static const String _baseUrl = 'https://api.openai.com/v1/audio/speech';
  
  static const String _apiKey = 'apikey';
  
  final AudioPlayer _audioPlayer = AudioPlayer();
  
  static const String _defaultVoice = 'alloy';
  
  static const String _defaultModel = 'gpt-4o-mini-tts';
  
  Future<bool> speak(String text, {
    String? voice,
    String? model,
    double speed = 1.0,
  }) async {
    try {
      debugPrint('ğŸ”Š OpenAI TTS: Starting speech synthesis');
      debugPrint('ğŸ”‘ API Key starts with: ${_apiKey.substring(0, 10)}...');
      
      if (text.trim().isEmpty) {
        debugPrint('âŒ OpenAI TTS: Empty text provided');
        return false;
      }
      
      debugPrint('ğŸ™ï¸ OpenAI TTS: Synthesizing text: "$text"');
      
      final improvedText = improveVietnamesePronunciation(text);
      debugPrint('ğŸ”§ Improved Vietnamese text: "$improvedText"');
      
      final Map<String, dynamic> payload = {
        'model': model ?? _defaultModel,
        'input': improvedText,
        'voice': voice ?? _defaultVoice,
        'response_format': 'mp3',
        'speed': speed.clamp(0.25, 4.0),
      };
      
      debugPrint('ğŸš€ OpenAI TTS: Making HTTP request to $_baseUrl');
      debugPrint('ğŸ“ Payload: ${jsonEncode(payload)}');
      
      final response = await http.post(
        Uri.parse(_baseUrl),
        headers: {
          'Content-Type': 'application/json',
          'Authorization': 'Bearer $_apiKey',
        },
        body: jsonEncode(payload),
      );
      
      debugPrint('ğŸ“Š OpenAI TTS: Response status: ${response.statusCode}');
      
      if (response.statusCode == 200) {
        debugPrint('âœ… OpenAI TTS: Received audio data');
        
        final Uint8List audioData = response.bodyBytes;
        debugPrint('ğŸ–» Audio data size: ${audioData.length} bytes');
        
        final Directory tempDir = await getTemporaryDirectory();
        final String tempPath = '${tempDir.path}/openai_tts_${DateTime.now().millisecondsSinceEpoch}.mp3';
        final File tempFile = File(tempPath);
        await tempFile.writeAsBytes(audioData);
        
        debugPrint('ğŸ’¾ File saved to: $tempPath');
        
        debugPrint('ğŸµ Playing audio...');
        await _audioPlayer.play(DeviceFileSource(tempPath));
        
        Future.delayed(const Duration(seconds: 10), () {
          if (tempFile.existsSync()) {
            tempFile.delete();
            debugPrint('ğŸ”„ Cleaned up temp file: $tempPath');
          }
        });
        
        debugPrint('âœ… OpenAI TTS: Audio played successfully');
        return true;
        
      } else {
        debugPrint('âŒ OpenAI TTS: HTTP Error ${response.statusCode}: ${response.body}');
        return false;
      }
      
    } catch (e) {
      debugPrint('ğŸš¨ OpenAI TTS: Exception occurred: $e');
      debugPrint('ğŸš¨ Stack trace: ${StackTrace.current}');
      return false;
    }
  }
  
  Future<void> stop() async {
    try {
      await _audioPlayer.stop();
      debugPrint('OpenAI TTS: Audio stopped');
    } catch (e) {
      debugPrint('OpenAI TTS: Error stopping audio: $e');
    }
  }
  
  Future<bool> testTTS() async {
    debugPrint('ğŸ§ª ğŸ¤ Testing OpenAI TTS...');
    final result = await speak('Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI thÃ´ng minh cá»§a báº¡n. Há»‡ thá»‘ng chuyá»ƒn vÄƒn báº£n thÃ nh giá»ng nÃ³i Ä‘Ã£ sáºµn sÃ ng hoáº¡t Ä‘á»™ng.');
    debugPrint('ğŸ§ª Test result: $result');
    return result;
  }
  
  static const Map<String, String> vietnameseTranslations = {
    'person': 'ngÆ°á»i',
    'man': 'Ä‘Ã n Ã´ng',
    'woman': 'phá»¥ ná»¯', 
    'child': 'tráº» em',
    'boy': 'con trai',
    'girl': 'con gÃ¡i',
    'baby': 'em bÃ©',
    'dog': 'con chÃ³',
    'cat': 'con mÃ¨o',
    'bird': 'con chim',
    'fish': 'con cÃ¡',
    
    'car': 'Ã´ tÃ´',
    'bicycle': 'xe Ä‘áº¡p',
    'motorbike': 'xe mÃ¡y',
    'motorcycle': 'xe mÃ¡y',
    'bus': 'xe buÃ½t',
    'train': 'tÃ u há»a',
    'truck': 'xe táº£i',
    'airplane': 'mÃ¡y bay',
    'boat': 'thuyá»n',
    
    'chair': 'cÃ¡i gháº¿',
    'table': 'cÃ¡i bÃ n',
    'bed': 'giÆ°á»ng ngá»§',
    'sofa': 'gháº¿ sÃ´ pha',
    'door': 'cá»­a ra vÃ o',
    'window': 'cá»­a sá»•',
    'lamp': 'Ä‘Ã¨n',
    'mirror': 'gÆ°Æ¡ng',
    
    'phone': 'Ä‘iá»‡n thoáº¡i',
    'mobile': 'Ä‘iá»‡n thoáº¡i di Ä‘á»™ng',
    'laptop': 'mÃ¡y tÃ­nh xÃ¡ch tay', 
    'computer': 'mÃ¡y tÃ­nh',
    'television': 'ti vi',
    'tv': 'ti vi',
    'monitor': 'mÃ n hÃ¬nh mÃ¡y tÃ­nh',
    'keyboard': 'bÃ n phÃ­m',
    'mouse': 'chuá»™t mÃ¡y tÃ­nh',
    'remote': 'Ä‘iá»u khiá»ƒn tá»« xa',
    'camera': 'mÃ¡y áº£nh',
    
    'apple': 'quáº£ tÃ¡o',
    'banana': 'quáº£ chuá»‘i',
    'orange': 'quáº£ cam',
    'rice': 'cÆ¡m',
    'bread': 'bÃ¡nh mÃ¬',
    'water': 'nÆ°á»›c',
    'coffee': 'cÃ  phÃª',
    'tea': 'trÃ ',
    'milk': 'sá»¯a',
    
    'book': 'quyá»ƒn sÃ¡ch',
    'pen': 'bÃºt',
    'pencil': 'bÃºt chÃ¬',
    'bag': 'cÃ¡i tÃºi',
    'backpack': 'ba lÃ´',
    'wallet': 'vÃ­ tiá»n',
    'watch': 'Ä‘á»“ng há»“ Ä‘eo tay',
    'clock': 'Ä‘á»“ng há»“ treo tÆ°á»ng',
    'glasses': 'kÃ­nh máº¯t',
    
    'cup': 'cÃ¡i cá»‘c',
    'glass': 'ly nÆ°á»›c',
    'bottle': 'chai nÆ°á»›c',
    'plate': 'Ä‘Ä©a Äƒn',
    'bowl': 'bÃ¡t Äƒn',
    'spoon': 'thÃ¬a Äƒn',
    'knife': 'dao',
    'fork': 'nÄ©a',
  };
  
  static String translateToVietnamese(String englishName) {
    final translated = vietnameseTranslations[englishName.toLowerCase()];
    if (translated != null) {
      return translated;
    }
    
    return 'Ä‘á»“ váº­t';
  }
  
  static String improveVietnamesePronunciation(String text) {
    String improved = text;
    
    improved = improved.replaceAll('vÃ ', 'vá»›i');
    improved = improved.replaceAll('cÃ¡c', 'nhá»¯ng');
    improved = improved.replaceAll('phÃ¡t hiá»‡n', 'tháº¥y cÃ³');
    improved = improved.replaceAll('váº­t thá»ƒ', 'Ä‘á»“ váº­t');
    
    if (!improved.endsWith('.') && !improved.endsWith('!') && !improved.endsWith('?')) {
      improved += '.';
    }
    
    return improved;
  }
  
  Future<bool> announceDetectedObjects(List<String> objects) async {
    if (objects.isEmpty) {
      return await speak('TÃ´i khÃ´ng tháº¥y váº­t thá»ƒ nÃ o cáº£.');
    }
    
    if (objects.length == 1) {
      final vietnameseName = translateToVietnamese(objects.first);
      return await speak('TÃ´i tháº¥y cÃ³ $vietnameseName.');
    }
    
    final vietnameseObjects = objects.map((obj) => translateToVietnamese(obj)).toList();
    
    if (objects.length == 2) {
      return await speak('TÃ´i tháº¥y cÃ³ ${vietnameseObjects[0]} vÃ  ${vietnameseObjects[1]}.');
    }
    
    final lastObject = vietnameseObjects.removeLast();
    final objectsList = vietnameseObjects.join(', ');
    return await speak('TÃ´i tháº¥y cÃ³ $objectsList vÃ  $lastObject.');
  }
  
  Future<bool> greetUser() async {
    final greetings = [
      'Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a báº¡n.',
      'ChÃ o báº¡n! TÃ´i sáºµn sÃ ng há»— trá»£ báº¡n.',
      'Xin chÃ o! HÃ´m nay tÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?',
    ];
    final greeting = greetings[DateTime.now().millisecond % greetings.length];
    return await speak(greeting);
  }
  
  Future<bool> announceCameraStatus(bool isActive) async {
    if (isActive) {
      return await speak('Camera Ä‘Ã£ Ä‘Æ°á»£c báº­t. TÃ´i cÃ³ thá»ƒ nhÃ¬n tháº¥y nhá»¯ng gÃ¬ báº¡n Ä‘ang nhÃ¬n.');
    } else {
      return await speak('Camera Ä‘Ã£ Ä‘Æ°á»£c táº¯t. TÃ´i khÃ´ng thá»ƒ nhÃ¬n tháº¥y gÃ¬ cáº£.');
    }
  }
  
  Future<bool> announceError(String error) async {
    return await speak('Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra. Vui lÃ²ng thá»­ láº¡i.');
  }
  
  Future<bool> announceNoObjectsDetected() async {
    final messages = [
      'TÃ´i khÃ´ng tháº¥y váº­t gÃ¬ Ä‘áº·c biá»‡t.',
      'KhÃ´ng cÃ³ gÃ¬ Ä‘á»ƒ bÃ¡o cÃ¡o.',
      'TÃ´i khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c váº­t thá»ƒ nÃ o.',
      'Khu vá»±c nÃ y trá»‘ng.',
    ];
    final message = messages[DateTime.now().millisecond % messages.length];
    return await speak(message);
  }
  
  void dispose() {
    _audioPlayer.dispose();
  }
}