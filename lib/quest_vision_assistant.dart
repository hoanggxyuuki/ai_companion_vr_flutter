import 'package:flutter/material.dart';
import 'package:ai_companion_vr_flutter/quest_frame_capture.dart';
import 'package:web_socket_channel/web_socket_channel.dart';
import 'package:ai_companion_vr_flutter/tts_manager.dart';
import 'package:ai_companion_vr_flutter/core/openai_tts_service.dart';
import 'dart:typed_data';
import 'dart:async';
import 'dart:convert';

class QuestVisionAssistant extends StatefulWidget {
  @override
  _QuestVisionAssistantState createState() => _QuestVisionAssistantState();
}

class _QuestVisionAssistantState extends State<QuestVisionAssistant> {
  Uint8List? currentFrame;
  String statusMessage = "üî• Quest 3S Vision Assistant Ready";
  bool isCapturing = false;
  bool isConnected = false;
  Timer? captureTimer;
  
  // WebSocket
  WebSocketChannel? _visionChannel;
  String serverUrl = "ws://172.20.10.3:8000"; // API server IP address
  
  // Camera - Single camera v·ªõi smooth display
  String? selectedCameraId;
  Map<String, dynamic>? cameraInfo;
  List<Map<String, dynamic>> availableCameras = [];
  
  // Camera frames - T√°ch display v√† processing
  Uint8List? displayFrame; // For UI display (smooth)
  Uint8List? processingFrame; // For AI processing (slower)
  
  // Frame counters ƒë·ªÉ t·ªëi ∆∞u
  int frameCount = 0;
  int aiProcessingInterval = 3; // Ch·ªâ g·ª≠i AI m·ªói 3 frames
  
  // Object Detection Results
  List<Map<String, dynamic>> detectedObjects = [];
  String lastDescription = "";
  
  // Text-to-Speech Manager
  final TTSManager _ttsManager = TTSManager.instance;
  bool isSpeaking = false;
  
  // TTS Throttling
  DateTime? lastTTSTime;
  String? lastSpokenContent;
  static const int TTS_COOLDOWN_SECONDS = 3; // Ch·ªâ n√≥i m·ªói 3 gi√¢y

  @override
  void initState() {
    super.initState();
    print('üöÄ Starting initState...');
    _initializeApp();
  }

  Future<void> _initializeApp() async {
    try {
      print('üöÄ Starting app initialization...');
      await _initializeTTSManager();
      await _initializeQuest3S();
      
      // T·ª± ƒë·ªông th·ª≠ connect (nh∆∞ng kh√¥ng ch·∫∑n n·∫øu l·ªói)
      print('ÔøΩ Attempting auto-connect...');
      await Future.delayed(Duration(seconds: 1));
      try {
        await _connectWebSocket();
        print('‚úÖ Auto-connect successful!');
        
        // T·ª± ƒë·ªông start AI vision n·∫øu connect th√†nh c√¥ng
        await Future.delayed(Duration(seconds: 1));
        if (isConnected && selectedCameraId != null) {
          print('üöÄ Auto-starting vision capture...');
          await _startVisionCapture();
        }
      } catch (e) {
        print('‚ö†Ô∏è Auto-connect failed: $e. User can manually start.');
        setState(() {
          statusMessage = "‚ö†Ô∏è Auto-connect failed. Use Start button to begin.";
        });
      }
    } catch (e) {
      print('‚ùå Error in _initializeApp: $e');
      setState(() {
        statusMessage = "‚ùå Initialization error: $e";
      });
    }
  }

  @override
  void dispose() {
    _stopVisionCapture();
    _visionChannel?.sink.close();
    _ttsManager.dispose();
    QuestFrameCapture.release();
    super.dispose();
  }

  Future<void> _initializeTTSManager() async {
    try {
      print('üöÄ Initializing TTS Manager...');
      await _ttsManager.initialize();
      print('‚úÖ TTS Manager initialized: ${_ttsManager.getStatus()}');
    } catch (e) {
      print('‚ùå TTS Manager initialization failed: $e');
    }
  }

  Future<void> _speak(String text) async {
    if (text.isNotEmpty && !isSpeaking) {
      setState(() {
        isSpeaking = true;
      });
      
      final success = await _ttsManager.speak(text);
      if (success) {
        // Wait for speaking to complete
        while (_ttsManager.isSpeaking) {
          await Future.delayed(Duration(milliseconds: 100));
        }
      }
      
      setState(() {
        isSpeaking = false;
      });
    }
  }

  Future<void> _initializeQuest3S() async {
    setState(() {
      statusMessage = "üî• Initializing Quest 3S...";
    });

    // Check permissions
    final permissions = await QuestFrameCapture.checkPermissions();
    if (permissions == null || permissions['granted'] != true) {
      setState(() {
        statusMessage = "‚ùå Need permissions - Click 'Request Permissions'";
      });
      return;
    }

    // Find passthrough camera
    final passthrough = await QuestFrameCapture.findPassthroughCamera();
    
    // List cameras
    final cameras = await QuestFrameCapture.listCameras();
    if (cameras != null) {
      setState(() {
        availableCameras = cameras;
      });
    }

    String? targetCamera;
    if (cameras != null) {
      for (var camera in cameras) {
        String id = camera['id'] as String;
        if (id == "50" || id == "51") {
          targetCamera = id;
          break;
        }
      }
    }

    if (targetCamera != null) {
      await _initializeCamera(targetCamera);
      
      setState(() {
        statusMessage = "‚úÖ Quest 3S Camera $targetCamera ready for smooth AI vision!";
      });
    } else {
      setState(() {
        statusMessage = "‚ö†Ô∏è Quest 3S passthrough cameras (50/51) not found";
      });
    }
  }

  Future<void> _initializeCamera(String cameraId) async {
    final result = await QuestFrameCapture.initializeCamera(cameraId: cameraId);
    if (result != null) {
      setState(() {
        cameraInfo = result;
        selectedCameraId = cameraId;
      });
    }
  }

  Future<void> _connectWebSocket() async {
    try {
      setState(() {
        statusMessage = "üîó Connecting to AI Vision Server...";
      });

      print('üîó Attempting to connect to: $serverUrl/ws/vision');
      
      _visionChannel = WebSocketChannel.connect(
        Uri.parse('$serverUrl/ws/vision'),
      );

      // Thi·∫øt l·∫≠p listener
      _visionChannel!.stream.listen(
        (data) {
          _handleWebSocketMessage(data);
        },
        onError: (error) {
          print('‚ùå WebSocket error: $error');
          setState(() {
            isConnected = false;
            statusMessage = "‚ùå WebSocket error: $error";
          });
        },
        onDone: () {
          print('üîå WebSocket connection closed');
          setState(() {
            isConnected = false;
            statusMessage = "üîå WebSocket disconnected";
          });
        },
      );

      // Ch·ªù m·ªôt ch√∫t ƒë·ªÉ connection ·ªïn ƒë·ªãnh
      await Future.delayed(Duration(milliseconds: 500));
      
      // Send ping to test connection
      print('üì§ Sending ping to test connection...');
      _visionChannel!.sink.add(json.encode({"type": "ping"}));
      
      // Ch·ªù pong response trong 5 gi√¢y
      print('‚è≥ Waiting for pong response...');
      await Future.delayed(Duration(seconds: 2));
      
      // Gi·∫£ ƒë·ªãnh connection th√†nh c√¥ng n·∫øu kh√¥ng c√≥ l·ªói
      setState(() {
        isConnected = true;
        statusMessage = "‚úÖ Connected to AI Vision Server!";
      });
      
      print('‚úÖ WebSocket connection established successfully');

    } catch (e) {
      print('‚ùå Connection failed: $e');
      setState(() {
        isConnected = false;
        statusMessage = "‚ùå Failed to connect: $e";
      });
      rethrow;
    }
  }

  void _handleWebSocketMessage(dynamic data) {
    try {
      final message = json.decode(data);
      
      if (message['type'] == 'pong') {
        // Connection confirmed
        return;
      }
      
      if (message['type'] == 'detections') {
        setState(() {
          detectedObjects = List<Map<String, dynamic>>.from(message['objects'] ?? []);
          lastDescription = message['description'] ?? '';
        });

        // Speak with throttling logic
        print('üîä Received detection data: description=${lastDescription.isNotEmpty}, objects=${detectedObjects.length}');
        print('üîä TTS Manager status: ${_ttsManager.getStatus()}');
        
        _handleTTSWithThrottling();
      }
      
      if (message['type'] == 'error') {
        setState(() {
          statusMessage = "üö® AI Error: ${message['message']}";
        });
      }
      
    } catch (e) {
      print("üö® Error parsing WebSocket message: $e");
    }
  }

  Future<void> _startVisionCapture() async {
    print('üé• Starting vision capture...');
    
    if (selectedCameraId == null) {
      print('‚ùå No camera selected');
      setState(() {
        statusMessage = "‚ùå No camera selected";
      });
      return;
    }
    
    if (!isConnected) {
      print('‚ùå Not connected to server');
      setState(() {
        statusMessage = "‚ùå Not connected to server";
      });
      return;
    }

    print('‚úÖ Camera: $selectedCameraId, Connected: $isConnected');
    setState(() {
      isCapturing = true;
      statusMessage = "üî• AI Vision Active - Analyzing environment...";
    });

    print('üé• Starting single timer capture with frame optimization...');
    
    // Single timer ƒë·ªÉ tr√°nh conflict - 200ms interval
    captureTimer = Timer.periodic(Duration(milliseconds: 200), (timer) async {
      if (!isCapturing) {
        timer.cancel();
        return;
      }
      
      try {
        final frame = await QuestFrameCapture.captureFrame();
        if (frame != null && mounted) {
          // Lu√¥n update UI ƒë·ªÉ m∆∞·ª£t
          setState(() {
            displayFrame = frame;
            currentFrame = frame;
          });
          
          // Ch·ªâ g·ª≠i AI m·ªói 5 frames (m·ªói 1 gi√¢y)
          frameCount++;
          if (frameCount % 5 == 0 && isConnected) {
            processingFrame = frame;
            final base64Frame = base64Encode(frame);
            print('üì§ Sending AI frame (${frame.length} bytes) - Count: $frameCount');
            _visionChannel!.sink.add(base64Frame);
          }
        }
      } catch (e) {
        print('‚ùå Capture error: $e');
        // N·∫øu c√≥ l·ªói, th·ª≠ reinitialize camera
        if (e.toString().contains('Session has been closed')) {
          print('üîÑ Reinitializing camera due to session error...');
          await _initializeCamera(selectedCameraId!);
        }
      }
    });
    
    print('‚úÖ Vision capture started successfully');
  }

  void _stopVisionCapture() {
    print('üõë Stopping vision capture...');
    
    // Cancel timer tr∆∞·ªõc
    captureTimer?.cancel();
    captureTimer = null;
    
    // Reset frame counter
    frameCount = 0;
    
    // Update state
    setState(() {
      isCapturing = false;
      statusMessage = "üî• Vision capture stopped";
    });
    
    print('‚úÖ Vision capture stopped successfully');
  }

  Future<void> _requestPermissions() async {
    final result = await QuestFrameCapture.requestPermissions();
    if (result != null && result['granted'] == true) {
      await _initializeQuest3S();
    }
  }

  void _handleTTSWithThrottling() {
    final now = DateTime.now();
    
    // Ki·ªÉm tra xem c√≥ ƒëang ph√°t √¢m thanh kh√¥ng
    if (_ttsManager.isSpeaking) {
      print('üîä TTS is currently speaking, skipping...');
      return;
    }
    
    // Ki·ªÉm tra cooldown
    if (lastTTSTime != null) {
      final timeSinceLastTTS = now.difference(lastTTSTime!);
      if (timeSinceLastTTS.inSeconds < TTS_COOLDOWN_SECONDS) {
        print('üîä TTS cooldown active (${timeSinceLastTTS.inSeconds}s), skipping...');
        return;
      }
    }
    
    String? contentToSpeak;
    
    // Quy·∫øt ƒë·ªãnh n√≥i g√¨
    if (lastDescription.isNotEmpty) {
      contentToSpeak = lastDescription;
    } else if (detectedObjects.isNotEmpty) {
      // Ch·ªâ l·∫•y v·∫≠t th·ªÉ c√≥ confidence cao
      final highConfidenceObjects = detectedObjects.where(
        (obj) => (obj['confidence'] ?? 0.0) > 0.7
      ).toList();
      
      if (highConfidenceObjects.isNotEmpty) {
        final objectNames = highConfidenceObjects.map((obj) => 
          OpenAITTSService.translateToVietnamese(obj['name'] as String)
        ).toSet().toList(); // D√πng Set ƒë·ªÉ lo·∫°i b·ªè tr√πng l·∫∑p
        
        if (objectNames.length == 1) {
          contentToSpeak = 'Ph√°t hi·ªán ${objectNames.first}';
        } else {
          contentToSpeak = 'Ph√°t hi·ªán ${objectNames.join(', ')}';
        }
      }
    }
    
    // Ki·ªÉm tra xem n·ªôi dung c√≥ kh√°c l·∫ßn tr∆∞·ªõc kh√¥ng
    if (contentToSpeak != null && contentToSpeak != lastSpokenContent) {
      print('üîä Speaking new content: $contentToSpeak');
      lastTTSTime = now;
      lastSpokenContent = contentToSpeak;
      
      // G·ªçi TTS
      _speakContent(contentToSpeak);
    } else if (contentToSpeak == lastSpokenContent) {
      print('üîä Content unchanged, skipping TTS');
    } else {
      print('üîä No significant content to speak');
    }
  }
  
  Future<void> _speakContent(String content) async {
    try {
      final openaiTts = OpenAITTSService();
      final success = await openaiTts.speak(content);
      if (!success) {
        print('üîä OpenAI TTS failed, trying local TTS...');
        await _ttsManager.speak(content);
      }
    } catch (e) {
      print('üîä TTS Error: $e');
    }
  }

  Future<void> _testTTS() async {
    print('üé§ Testing TTS button pressed!');
    
    // Test OpenAI TTS directly
    try {
      final openaiTts = OpenAITTSService();
      print('üé§ Created OpenAI TTS service');
      final result = await openaiTts.testTTS();
      print('üé§ OpenAI TTS Test result: $result');
    } catch (e) {
      print('üé§ Direct OpenAI TTS Error: $e');
    }
    
    print('üé§ TTS Manager status: ${_ttsManager.getStatus()}');
    final result = await _ttsManager.testTTS();
    print('üé§ TTS Test result: $result');
  }

  Future<void> _startAIVision() async {
    print('üöÄ Start AI Vision button pressed!');
    
    if (isCapturing) {
      // Stop vision if running
      _stopVisionCapture();
      return;
    }
    
    // Step 1: Connect to WebSocket if not connected
    if (!isConnected) {
      setState(() {
        statusMessage = "üîó Connecting to AI server...";
      });
      
      try {
        await _connectWebSocket();
        if (!isConnected) {
          setState(() {
            statusMessage = "‚ùå Failed to connect to AI server";
          });
          return;
        }
      } catch (e) {
        setState(() {
          statusMessage = "‚ùå Connection error: $e";
        });
        return;
      }
    }
    
    // Step 2: Start vision capture
    if (selectedCameraId != null && isConnected) {
      await _startVisionCapture();
    } else {
      setState(() {
        statusMessage = "‚ùå Camera not ready or connection failed";
      });
    }
  }

  Widget _buildSmoothCameraView() {
    return Container(
      width: double.infinity,
      decoration: BoxDecoration(
        border: Border.all(color: Colors.cyan.withOpacity(0.4), width: 2),
        borderRadius: BorderRadius.circular(12),
        boxShadow: [
          BoxShadow(
            color: Colors.cyan.withOpacity(0.2),
            blurRadius: 10,
            spreadRadius: 2,
          ),
        ],
      ),
      child: ClipRRect(
        borderRadius: BorderRadius.circular(12),
        child: Stack(
          children: [
            // Main camera view
            Positioned.fill(
              child: Image.memory(
                currentFrame!,
                fit: BoxFit.cover,
              ),
            ),
            // Performance indicator
            Positioned(
              top: 12,
              right: 12,
              child: Container(
                padding: EdgeInsets.symmetric(horizontal: 8, vertical: 4),
                decoration: BoxDecoration(
                  color: Colors.black.withOpacity(0.7),
                  borderRadius: BorderRadius.circular(16),
                ),
                child: Row(
                  mainAxisSize: MainAxisSize.min,
                  children: [
                    Container(
                      width: 8,
                      height: 8,
                      decoration: BoxDecoration(
                        color: isCapturing ? Colors.green : Colors.red,
                        shape: BoxShape.circle,
                      ),
                    ),
                    SizedBox(width: 6),
                    Text(
                      "5 FPS",
                      style: TextStyle(
                        color: Colors.white,
                        fontSize: 12,
                        fontWeight: FontWeight.bold,
                      ),
                    ),
                  ],
                ),
              ),
            ),
            // AI processing indicator
            Positioned(
              bottom: 12,
              left: 12,
              child: Container(
                padding: EdgeInsets.symmetric(horizontal: 8, vertical: 4),
                decoration: BoxDecoration(
                  color: Colors.blue.withOpacity(0.8),
                  borderRadius: BorderRadius.circular(16),
                ),
                child: Text(
                  "ü§ñ AI: ${frameCount} frames",
                  style: TextStyle(
                    color: Colors.white,
                    fontSize: 12,
                    fontWeight: FontWeight.bold,
                  ),
                ),
              ),
            ),
          ],
        ),
      ),
    );
  }

  Widget _buildDetectionResults() {
    if (detectedObjects.isEmpty && lastDescription.isEmpty) {
      return Container(
        padding: EdgeInsets.all(16), // Gi·∫£m padding ƒë·ªÉ t·ªëi ∆∞u kh√¥ng gian
        child: Text(
          "üëÅÔ∏è AI Vision is analyzing what you see...",
          style: TextStyle(color: Colors.white70, fontSize: 16), // Gi·∫£m font size
          textAlign: TextAlign.center,
        ),
      );
    }

    return Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        if (lastDescription.isNotEmpty) ...[
          Container(
            width: double.infinity,
            padding: EdgeInsets.all(20), // TƒÉng padding
            decoration: BoxDecoration(
              color: Colors.blue.withOpacity(0.3),
              borderRadius: BorderRadius.circular(12), // Bo tr√≤n nhi·ªÅu h∆°n
            ),
            child: Column(
              crossAxisAlignment: CrossAxisAlignment.start,
              children: [
                Text(
                  "üéØ AI Analysis:",
                  style: TextStyle(color: Colors.blue, fontWeight: FontWeight.bold, fontSize: 16), // Compact font
                ),
                SizedBox(height: 8), // Compact spacing
                Text(
                  lastDescription,
                  style: TextStyle(color: Colors.white, fontSize: 14), // Compact font
                ),
              ],
            ),
          ),
          SizedBox(height: 12), // Compact spacing
        ],
        
        if (detectedObjects.isNotEmpty) ...[
          Text(
            "üîç Detected Objects:",
            style: TextStyle(color: Colors.white, fontWeight: FontWeight.bold, fontSize: 16), // Compact font
          ),
          SizedBox(height: 8), // Compact spacing
          ...detectedObjects.take(3).map((obj) { // Ch·ªâ hi·ªÉn th·ªã 3 objects ƒë·ªÉ ti·∫øt ki·ªám space
            return Container(
              margin: EdgeInsets.only(bottom: 8), // Compact margin
              padding: EdgeInsets.all(12), // Compact padding
              decoration: BoxDecoration(
                color: Colors.green.withOpacity(0.2),
                borderRadius: BorderRadius.circular(10), // Bo tr√≤n nhi·ªÅu h∆°n
              ),
              child: Row(
                children: [
                  Text(
                    "${obj['name'] ?? 'Unknown'}",
                    style: TextStyle(color: Colors.white, fontWeight: FontWeight.bold, fontSize: 14), // Compact font
                  ),
                  Spacer(),
                  Text(
                    "${((obj['confidence'] ?? 0.0) * 100).toStringAsFixed(1)}%",
                    style: TextStyle(color: Colors.green, fontSize: 12), // Compact font
                  ),
                ],
              ),
            );
          }).toList(),
        ],
      ],
    );
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: Colors.black,
      body: SafeArea(
        child: Padding(
          padding: EdgeInsets.all(16.0), // Gi·∫£m padding ƒë·ªÉ t·ªëi ∆∞u kh√¥ng gian
          child: Column(
            children: [
              // Status - to h∆°n
              Container(
                width: double.infinity,
                padding: EdgeInsets.all(24), // TƒÉng padding
                decoration: BoxDecoration(
                  color: Colors.white.withOpacity(0.1),
                  borderRadius: BorderRadius.circular(12),
                ),
                child: Text(
                  statusMessage,
                  style: TextStyle(color: Colors.white, fontSize: 20), // TƒÉng font size
                  textAlign: TextAlign.center,
                ),
              ),
              SizedBox(height: 24), // TƒÉng spacing

              // Connection Status - to h∆°n
              Row(
                children: [
                  Container(
                    width: 16, // TƒÉng size indicator
                    height: 16,
                    decoration: BoxDecoration(
                      color: isConnected ? Colors.green : Colors.red,
                      shape: BoxShape.circle,
                    ),
                  ),
                  SizedBox(width: 12),
                  Text(
                    isConnected ? "üîó AI + OpenAI TTS Ready" : "üîå Disconnected",
                    style: TextStyle(color: Colors.white70, fontSize: 18), // TƒÉng font size
                  ),
                  Spacer(),
                  if (_ttsManager.isSpeaking)
                    Row(
                      children: [
                        Icon(Icons.volume_up, color: Colors.green, size: 20), // TƒÉng icon size
                        SizedBox(width: 6),
                        Text("üîä OpenAI TTS...", style: TextStyle(color: Colors.green, fontSize: 16)),
                      ],
                    ),
                ],
              ),
              SizedBox(height: 24),

              // Camera Preview - Single smooth camera
              if (currentFrame != null) ...[
                Expanded(
                  flex: 4, // Camera chi·∫øm 80% m√†n h√¨nh
                  child: _buildSmoothCameraView(),
                ),
                SizedBox(height: 16),
              ],

              // Detection Results - compact
              Expanded(
                flex: 1, // Gi·∫£m flex ƒë·ªÉ camera chi·∫øm nhi·ªÅu kh√¥ng gian h∆°n
                child: SingleChildScrollView(
                  child: _buildDetectionResults(),
                ),
              ),

              SizedBox(height: 16),

              // Controls - Setup v√† Start buttons
              Row(
                mainAxisAlignment: MainAxisAlignment.spaceEvenly,
                children: [
                  // Setup button
                  Expanded(
                    child: Padding(
                      padding: EdgeInsets.only(right: 8),
                      child: ElevatedButton.icon(
                        onPressed: _requestPermissions,
                        icon: Icon(Icons.settings, size: 24),
                        label: Text("Setup", style: TextStyle(fontSize: 18)),
                        style: ElevatedButton.styleFrom(
                          backgroundColor: Colors.orange,
                          padding: EdgeInsets.symmetric(horizontal: 24, vertical: 16),
                          shape: RoundedRectangleBorder(
                            borderRadius: BorderRadius.circular(12),
                          ),
                        ),
                      ),
                    ),
                  ),
                  // Start button
                  Expanded(
                    child: Padding(
                      padding: EdgeInsets.only(left: 8),
                      child: ElevatedButton.icon(
                        onPressed: _startAIVision,
                        icon: Icon(
                          isCapturing ? Icons.stop : Icons.play_arrow, 
                          size: 24
                        ),
                        label: Text(
                          isCapturing ? "Stop AI" : "Start AI", 
                          style: TextStyle(fontSize: 18)
                        ),
                        style: ElevatedButton.styleFrom(
                          backgroundColor: isCapturing ? Colors.red : Colors.green,
                          padding: EdgeInsets.symmetric(horizontal: 24, vertical: 16),
                          shape: RoundedRectangleBorder(
                            borderRadius: BorderRadius.circular(12),
                          ),
                        ),
                      ),
                    ),
                  ),
                ],
              ),
            ],
          ),
        ),
      ),
    );
  }
}